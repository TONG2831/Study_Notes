## Redis
#### 数据结构
> Redis对外提供了5种数据结构分别是 string、hash、list、set、zset.这5中对外的数据结构,底层是由六种数据结构支撑的.

[参考博客园](https://www.cnblogs.com/ysocean/p/9102811.html#_label0)

###### SDS 动态字符串

SDS的结构定义

```
struct sdshdr{
     //记录buf数组中已使用字节的数量
     //等于 SDS 保存字符串的长度
     int len;
     //记录 buf 数组中未使用字节的数量
     int free;
     //字节数组，用于保存字符串
     char buf[];
}
```
特点:

1. O(1)复杂度读取字符串长度

   sds在结构中已经记录的存储的字符串长度,所以时间复杂度为O(1).而C语言中,获取长度是通过指针比遍历计数实现的. 
   
2. 杜绝缓冲区溢出
    
    c语言修改字符串使用`strcat`来拼接字符串,一旦没有足够长度的内存空间,导致内存溢出.而SDS会根据len和free属性检查,不满足的情况下先扩容,然后修改,不会导致内存溢出.

3. 减少修改字符串的内存分配次数

    C语言中,修改字符串,是先释放内存再重新申请.如果是拼接操作,需要申请足够的内存,否则造成内存溢出;如果是截取操作,需要释放不再需要的内存,否则会造成内存泄露.频繁的内粗释放申请操作,带来更多的系统开销.
    
    而SDS在拼接时会先检查然后扩容,截取操作时,对于不再使用的内存空间,由free属性记录,不会造成内存泄露.
    
    对于未使用空间,SDS使用了空间预分配和惰性空间释放两种优化策略:
    - 空间预分配 用于字符串增加操作.如果修改后,字符串长度(len属性)小于1M,那么程序分配和len属性大小相同的未使用空间.如果大于1M,那么程序分配1M的未使用空间.扩展SDS空间之前,会先检查内存是否够用,够用则不必扩展内存.
    - 惰性空间释放 用于优化SDS的字符串缩短操作.当SDS字符串缩短时,程序不立即使用内存分配来回收缩短之后多出来的字节空间,而是使用free将这些字节记录起来,供以后使用.
4. 二进制安全
    
    C语言字符串使用空字符结尾,那么对于可能包含空字符的二进制文件(图片等),C字符串讲无法提取,而SDS是通过len来读取字符串,更为安全.
5. 兼容部分C字符串函数
    
    虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库<string.h> 中的一部分函数。




###### 链表
> 链表提供了高效的节点重排能力,以及顺序性的节点访问方式,并且可以通过增删来调整链表的长度.

定义

```
typedef  struct listNode{
       //前置节点
       struct listNode *prev;
       //后置节点
       struct listNode *next;
       //节点的值
       void *value;  
}listNode

typedef struct list{
     //表头节点
     listNode *head;
     //表尾节点
     listNode *tail;
     //链表所包含的节点数量
     unsigned long len;
     //节点值复制函数
     void (*free) (void *ptr);
     //节点值释放函数
     void (*free) (void *ptr);
     //节点值对比函数
     int (*match) (void *ptr,void *key);
}list;

```

特点
1. 链表广泛应用于各种功能,如列表键,发布订阅,慢查询,监视器.
2. 存储了链表的头结点,尾节点和链表的长度,时间复杂度O(1)
3. 无环链表,链表的头结点的前置结点和为节点的后置结点都指向NULL.



###### 字典 hash
> 字典又称符号表,关联数组,或映射(map).字典中的每一个key都是唯一的,通过key可以对值惊醒查找修改.参考HashMap.C语言中没有字典的数据结构,都是Redis自己实现的.Redis数据库底层就是使用字典实现.

```
typedef struct dictht{
     //哈希表数组
     dictEntry **table;
     //哈希表大小
     unsigned long size;
     //哈希表大小掩码，用于计算索引值
     //总是等于 size-1
     unsigned long sizemask;
     //该哈希表已有节点的数量
     unsigned long used;
 
}dictht

typedef struct dictEntry{
     //键
     void *key;
     //值
     union{
          void *val;
          uint64_tu64;
          int64_ts64;
     }v;
 
     //指向下一个哈希表节点，形成链表
     struct dictEntry *next;
}dictEntry

```
特点:

1. 负载因子 = 已使用的节点/哈希表的大小
2. hash算法 通过对key做hash计算,然后做&运算,可以得到该key在数组中的位置.
3. hash碰撞 当有两个或以上的键被分配在哈希数组的同一个下标位置时,认为发生了hash碰撞,这是因为不同key通过hash算法可能得到相同的hashcode值.解决办法:开放地址法和链地址法
3. rehash  hash表的扩展与收缩.<br> 满足以下条件,会对hash标执行扩展操作:
    - 服务器没有执行BGSAVE或者BGREWRITEAOF命令,并且hash表的负载因子大于等于1
    - 服务器正在执行BGSAVE或者BGREWRITEAOF命令,并且hash标的负载因子大于等于5
    <br><br>
    收缩: 当hash表的负载因子小于0.1时,程序自动对hash表执行收缩操作
4. 渐进式rehash
    在执行扩展与收缩操作时,如果键值对过多,一次性完成可能会导致服务器在一段时间内停止服务.所以采用渐进式rehash,即在rehash期间查找,删除,更新操作会在ht[0]哈希表中进行,如果在ht[0]中没有查找到,则在ht[1]中继续查找.


###### 跳跃表
> 跳跃表是一种有序的数据结构,它通过在每个节点中维持多个指向其他节点的指针,实现快速访问节点的目的.两个地方用到跳跃表,一个是有序集合键,一个是集群节点中用作数据结构.

> 跳跃表支持平均O(logN),最差O(n)的时间复杂度查找

> 在大部分情况下,跳跃表的效率可以和平衡树相媲美,并且因为跳跃表的实现相相对简单,不少程序使用跳跃表代替平衡术

> Redis使用跳跃表作为有序集合键的底层实现之一,如果一个集合的元素较多,又或者有序集合中元素的成员是比较长的字符串时,会使用跳跃表

定义

```
typedef struct zskiplistNode {
     //层
     struct zskiplistLevel{
           //前进指针
           struct zskiplistNode *forward;
           //跨度
           unsigned int span;
     }level[];
 
     //后退指针
     struct zskiplistNode *backward;
     //分值
     double score;
     //成员对象
     robj *obj;
 
} zskiplistNode

typedef struct zskiplist{
     //表头节点和表尾节点
     structz skiplistNode *header, *tail;
     //表中节点的数量
     unsigned long length;
     //表中层数最大的节点的层数
     int level;
 
}zskiplist;
```
可以看到,跳跃表的基础结构与链表十分相似.

常规操作

　①、搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。

　　②、插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。

　　③、删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。


总结:

1. 跳跃表式有序集合键的底层实现之一
2. 每个跳跃表的节点的层高都是1~32
3. 在同一个跳跃表中,多个节点可以包含相同的分值,但是每个节点的成员对象必须是唯一的.
4. 跳跃表的节点按照分值大小进行排序,如果分值相同,节点按照成员对象的大小地进行排序.



###### 整数集合
> 整数集合是集合键的底层实现之一,当一个集合中只包含整数值元素,并且元素的数量不多时,会使用该结构.

```
typedef struct intset{
     //编码方式
     uint32_t encoding;
     //集合包含的元素数量
     uint32_t length;
     //保存元素的数组
     int8_t contents[];
 
}intset;

```
encoding 支持`INTSET_ENC_INT16`,`INTSET_ENC_INT32`,`INTSET_ENC_INT64`,数字表示位数.

特点:

1. 整数集合有序,从小到大
2. 整数集合每个元素都是唯一的
3. 当存储的新元素比当前集合中现有的所有元素的类型都要长时,整数集合需要升级,然后才能将新元素添加到整数集合中.依次从`INTSET_ENC_INT16`,`INTSET_ENC_INT32`,`INTSET_ENC_INT64.
4. 降级 INTSET不支持降级,升级之后会保持encoding


优点:

- 提升灵活性
    整数集合可以自适应升级适应新元素,可以随意的将`INTSET_ENC_INT16`,`INTSET_ENC_INT32`,`INTSET_ENC_INT64.编码的整数存放进去,不担心出错.
- 节省内存空间
    因为升级,所以存储时,会从较小的数据类型开始,升级操作只有在需要的时候才会进行,一定程度上节省内存空间.




###### 压缩列表
> 压缩列表是Redis为了解决内存而开发的,由一系列特殊编码的连续内存块组成的顺序性结构.

列表的构成:

![image](\images\压缩列表.png)

节点的构成:

![image](\images\压缩列表节点.png)

- previous_entry_length:记录前置节点的长度,根据该长度可以得到前置结点的起始地址,从而实现倒序遍历.记录压缩列表前一个字节的长度。previous_entry_ength的长度可能是1个字节或者是5个字节，如果上一个节点的长度小于254，则该节点只需要一个字节就可以表示前一个节点的长度了，如果前一个节点的长度大于等于254，则previous length的第一个字节为254，后面用四个字节表示当前节点前一个节点的长度。利用此原理即当前节点位置减去上一个节点的长度即得到上一个节点的起始位置，压缩列表可以从尾部向头部遍历。这么做很有效地减少了内存的浪费.
- encoding：节点的encoding保存的是节点的content的内容类型以及长度，encoding类型一共有两种，一种字节数组一种是整数，encoding区域长度为1字节、2字节或者5字节长。
- content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。


连锁更新

压缩列表的当前节点(entry1，entry2...entryn)的大小都介于 251~253，所以记录这些节点的长度只需要1个字节长度的previous_entry_length,现在要在表头节点前插入一个新的节点new,节点的长度为254，此时entry1节点的previous_entry_length就需要5个字节,而整个entry1节点的长度也超过253字节,从而引发后面的节点都需要更新.

删除节点同样引发当前问题


总结:

1. 压缩列表是一种为节约内存而开发的连续内存空间的顺序型结构
2. 压缩列表的作为列表键和哈希键的底层实现之一.当一个列表键只存储少量的元素,并且元素类型要么是小整数型,要么就是长度较小的字符串,此时选择压缩列表.另外,当一个哈希键存储较少的键值对,并且每个键值对的key和value都是小整数或者较短的字符串,就采用压缩列表.
3. 压缩列表可以存储多个节点,每个节点可以保存一个字节数组或者一个数字
4. 添加新的节点到压缩列表,或者从压缩列表中删除节点,可能引发连锁更新操作,但这种操作出现的几率不是很高.


###### 五种数据结构的底层实现

1.字符串

    编码: 
    
    int编码,保存long型整数,浮点型数据使用字符串,超过long的范围自动转为raw
    
    raw编码,保存长度大于44字节的字符串
    
    embstr编码,保存长度小于44 字节的字符串,修改时转为raw
    
    embstr与raw都使用redisObject和sds保存数据，区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）


2.列表

    编码:
    
    ziplist
    
    linkedlist
    
    
    当同时满足下面两个条件时，使用ziplist（压缩列表）编码：
    
    　　1、列表保存元素个数小于512个
    
    　　2、每个元素长度小于64字节
    
    　　不能满足这两个条件的时候使用 linkedlist 编码。

3.哈希对象
    
    编码:
    
    字典
    
    压缩列表
    
    和上面列表对象使用 ziplist 编码一样，当同时满足下面两个条件时，使用ziplist（压缩列表）编码：
    
    　　1、列表保存元素个数小于512个
    
    　　2、每个元素长度小于64字节

　　
4.集合

    编码: 采用intset和hashtable
    
    hashtable 编码的集合对象使用 字典作为底层实现，字典的每个键都是一个字符串对象，这里的每个字符串对象就是一个集合中的元素，而字典的值则全部设置为 null。这里可以类比Java集合中HashSet 集合的实现，HashSet 集合是由 HashMap 来实现的，集合中的元素就是 HashMap 的key，而 HashMap 的值都设为 null。
    
     当集合同时满足以下两个条件时，使用 intset 编码:
     　1、集合对象中所有元素都是整数
       2、集合对象所有元素数量不超过512
    
    
5.有序集合
    
    编码: 采用跳跃表和压缩列表
    
    ziplist 编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。并且压缩列表内的集合元素按分值从小到大的顺序进行排列，小的放置在靠近表头的位置，大的放置在靠近表尾的位置。
    
    skiplist 编码的有序集合对象使用 zet 结构作为底层实现，一个 zset 结构同时包含一个字典和一个跳跃表：

```
typedef struct zset{
     //跳跃表
     zskiplist *zsl;
     //字典
     dict *dice;
} zset;
```
　　字典的键保存元素的值，字典的值则保存元素的分值；跳跃表节点的 object 属性保存元素的成员，跳跃表节点的 score 属性保存元素的分值。

　　这两种数据结构会通过指针来共享相同元素的成员和分值，所以不会产生重复成员和分值，造成内存的浪费。

　　说明：其实有序集合单独使用字典或跳跃表其中一种数据结构都可以实现，但是这里使用两种数据结构组合起来，原因是假如我们单独使用 字典，虽然能以 O(1) 的时间复杂度查找成员的分值，但是因为字典是以无序的方式来保存集合元素，所以每次进行范围操作的时候都要进行排序；假如我们单独使用跳跃表来实现，虽然能执行范围操作，但是查找操作有 O(1)的复杂度变为了O(logN)。因此Redis使用了两种数据结构来共同实现有序集合。
　

当有序集合对象同时满足以下两个条件时，对象使用 ziplist 编码：

　　1、保存的元素数量小于128；

　　2、保存的所有元素长度都小于64字节。
    
 
 
    
    
    
    
    



#### 持久化机制

###### RDB (Redis Database)
> RDB持久化是将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当Redis重新启动时，可以读取快照文件恢复数据。二进制文件

触发条件

1. 自动触发
    
    save m n (指定当m秒钟发生n次变化时,触发持久化操作),在配置文件中配置,可以配置多条,多条时,只需要满足一个就可以.
    
    三个要素: serverCron函数、dirty计数器、和lastsave时间戳

    serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查 save m n 配置的条件是否满足，如果满足就执行bgsave.
    
    dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。注意dirty记录的是服务器进行了多少次修改，而不是客户端执行了多少修改数据的命令。
    
    lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。
    
    每个save m n的需满足两个条件:
    
    (1). 当前时间-lastsave时间戳>m
    
    (2). dirty>=n
    
    其他自动触发机制
除了save m n 以外，还有一些其他情况会触发bgsave：
在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点
执行shutdown命令时，自动执行rdb持久化

2. 手动触发

    save命令和bgsave命令都可以生成RDB文件。
    save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。
    
    save
    
    而bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。
    
    bgsave
    
    bgsave命令执行过程中，只有fork子进程时会阻塞服务器，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，线上环境要杜绝save的使用；后文中也将只介绍bgsave命令。此外，在自动触发RDB持久化时，Redis也会选择bgsave而不是save来进行持久化。


**bgsave**

bgsave原理是fork() + copyonwrite

fork：

fork()用于创建一个子进程，注意是子进程，不是子线程。fork()出来的进程共享其父类的内存数据。仅仅是共享fork()出子进程的那一刻的内存数据，后期主进程修改数据对子进程不可见，同理，子进程修改的数据对主进程也不可见。

copyonwrite（写时拷贝技术）：

主进程fork()子进程之后，内核把主进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向主进程。这也就是共享了主进程的内存，当其中某个进程写内存时(这里肯定是主进程写，因为子进程只负责rdb文件持久化工作，不参与客户端的请求)，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入内核的一个中断例程。

中断例程中，内核就会把触发的异常的页复制一份（这里仅仅复制异常页，也就是所修改的那个数据页，而不是内存中的全部数据），于是主子进程各自持有独立的一份








###### AOF(Append Only File)
> AOF是讲Redis执行的每次写命令记录到单独的日志文件;当Redis 重启时再次执行AOF文件中的命令恢复数据.

参考[：AOF](https://mp.weixin.qq.com/s/SODJ9Bvk-PLUpH0frzsstw)

AOF 持久化功能的实现可以分为命令追加( append )、文件写入( write )、文件同步( sync )、文件重写(rewrite)和重启加载(load)。其流程如下：

- 所有的写命令都会追加到AOF缓冲区
- 缓冲区根据相应的策略向磁盘进行同步操作
- 随着AOF越来越大,需要定期对AOF文件重写,达到压缩的目的
- 当Redis重启的时候,可以加载AOF文件进行数据恢复(Redis默认优先加载AOF)


**命令追加**

执行写命令时，会以RESP协议（即 Redis 客户端和服务器交互的通信协议）的形式追加到AOF缓冲区的末尾.

比如说 SET mykey myvalue 这条命令就以如下格式记录到 AOF 缓冲中。
```
"*3\r\n$3\r\nSET\r\n$5\r\nmykey\r\n$7\r\nmyvalue\r\n"
```
Redis 协议格式本文不再赘述，AOF之所以直接采用文本协议格式，是因为所有写入命令都要进行追加操作，直接采用协议格式，避免了二次处理开销。

**文件写入和同步**

`appendfsync`配置决定了文件写入的时机和频次。

- always：Redis 在每个事件循环都要将 AOF 缓冲区中的所有内容写入到 AOF 文件，并且同步 AOF 文件，所以 always 的效率是 appendfsync 选项三个值当中最差的一个，但从安全性来说，也是最安全的。当发生故障停机时，AOF 持久化也只会丢失一个事件循环中所产生的命令数据。

- everysec：Redis 在每个事件循环都要将 AOF 缓冲区中的所有内容写入到 AOF 文件中，并且每隔一秒就要在子线程中对 AOF 文件进行一次同步。从效率上看，该模式足够快。当发生故障停机时，只会丢失一秒钟的命令数据。

- no：Redis 在每一个事件循环都要将 AOF 缓冲区中的所有内容写入到 AOF 文件。而 AOF 文件的同步由操作系统控制。这种模式下速度最快，但是同步的时间间隔较长，出现故障时可能会丢失较多数据。


Linux 系统下 write 操作会触发延迟写( delayed write )机制。Linux 在内核提供页缓存区用来提供硬盘 IO 性能。write 操作在写入系统缓冲区之后直接返回。同步硬盘操作依赖于系统调度机制，例如：缓冲区页空间写满或者达到特定时间周期。同步文件之前，如果此时系统故障宕机，缓冲区内数据将丢失。

而 fsync 针对单个文件操作，对其进行强制硬盘同步， fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。

appendfsync的三个值代表着三种不同的调用 fsync的策略。调用 fsync周期越频繁，读写效率就越差，但是相应的安全性越高，发生宕机时丢失的数据越少。


**AOF数据恢复**

将AOF文件中的命令都执行一遍。

- 创建一个不带网络连接的的伪客户端( fake client)，因为 Redis 的命令只能在客户端上下文中执行，而载入 AOF 文件时所使用的的命令直接来源于 AOF 文件而不是网络连接，所以服务器使用了一个没有网络连接的伪客户端来执行 AOF 文件保存的写命令，伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样的。

- 从 AOF 文件中分析并取出一条写命令。

- 使用伪客户端执行被读出的写命令。

- 一直执行步骤 2 和步骤3，直到 AOF 文件中的所有写命令都被处理完毕为止。


**AOF 文件重写**

为了解决 AOF 文件体积膨胀的问题，Redis 提供了 AOF 文件重写( rewrite) 功能。通过该功能，Redis 可以创建一个新的 AOF 文件来替代现有的 AOF 文件。新旧两个 AOF 文件所保存的 Redis 状态相同，但是新的 AOF 文件不会包含任何浪费空间的荣誉命令，所以新 AOF 文件的体积通常比旧 AOF 文件的体积要小得很多。

实现原理

AOF 文件重写并不需要对现有的 AOF 文件进行任何读取、分析或者写入操作，而是通过读取服务器当前的数据库状态来实现的。首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令，这就是 AOF 重写功能的实现原理

缓冲区问题

在实际过程中，为了避免在执行命令时造成客户端输入缓冲区溢出，AOF 重写在处理列表、哈希表、集合和有序集合这四种可能会带有多个元素的键时，会先检查键所包含的元素数量，如果数量超过 REDISAOFREWRITEITEMSPER_CMD ( 一般为64 )常量，则使用多条命令记录该键的值，而不是一条命令。


rewrite触发机制

- 手动调用 bgrewriteaof 命令，如果当前有正在运行的 rewrite 子进程，则本次rewrite 会推迟执行，否则，直接触发一次 rewrite。

- 通过配置指令手动开启 AOF 功能，如果没有 RDB 子进程的情况下，会触发一次 rewrite，将当前数据库中的数据写入 rewrite 文件。

- 在 Redis 定时器中，如果有需要退出执行的 rewrite 并且没有正在运行的 RDB 或者 rewrite 子进程时，触发一次或者 AOF 文件大小已经到达配置的 rewrite 条件也会自动触发一次。


**AOF 后台重写**

Redis在子进程中进行AOF重写操作

- 子进程执行AOF重写期间，Redis进程可以正常处理客户端请求命令
- 子进程带有父进程的内存数据拷贝副本，不使用索，可以保证数据安全

问题：

在AOF文件重写期间， Redis仍然在对数据库的数据进行修改，导致数据库现有数据状态和AOF文件不一致。

为此Redis创建一个AOF重写缓冲区，Redis进程执行的写命令会同时同步给 AOF缓冲区和AOF重写缓冲区。

当子进程完成AOF重写之后，向父进程发送信号，然后父进程会调用信号处理函数（此函数阻塞主进程）做如下操作：
- 将AOF重写缓冲区的内容，写入到新的AOF文件中，
- 对AOF文件改名，直接覆盖现有的AOF文件，完成新旧文件的替换。
- 继续执行redis客户端的命令

阻塞问题

只有在调用信号处理函数时，进程阻塞。所以在AOF文件重写期间，redis的写命令在AOF缓冲区，依旧会写到旧的AOF文件中。

#### 事务

redis支持事务.
redis 通过Multi,Exec,Watch来实现事务的功能.

MULTI表示开启事务,EXEC表示提交事务.事务当中命令需要入队列,采用FIFO(先进先出)原则.

锁

事务采用WATCH的乐观锁,保证数据安全.在事务开始前,通过watch命令开启对key的监控,如何在exec命令提交之前被监控键已经被修改,则提交exec时,事务提交失败.

原子性

和传统关系型数据库相比我们认为Redis不具备原子性,因为执行exec时,如果有命令执行失败,是因为程序的逻辑性错误(如使用哈希键的命令操作字符串),只有当前命令执行失败,不会影响下面命令的执行.这与我们认识的原子性不相同.但,提交的命令在入队列发生错误(命令不存在,命令的格式不正确),在提交事务时,会被拒绝提交.

一致性

redis的事务在入队错误和执行错误时,保证一致性

隔离性

单进程和单线程保证隔离性

永久性

redis的持久化机制保证其持久性



#### 主从、哨兵、集群

###### 主从

> 主从模式下为一主多从

特点

    1.读写分离,可以通过扩展从节点,缓解读取数据的压力
    2.一主多从的情况下,从节点过多,对于同步数据压力较大.
    3.主从节点的宕机,需要人为介入
    4.单机的存储能力
    5.单机的写能力
    

**部分同步和全部同步的问题:**

旧版本的复制功能:

    1. 从服务器向主服务器发送SYNC命令
    2. 主服务器接收到SYNC命令之后执行BGSAVE命令,在后台生成RDB文件,将RDB文件发送给从服务器,
    3. 从服务器接受RDB文件并载入数据
    4. 主服务器将记在缓冲区的所有命令发给从服务器,从服务器更新状态.

在发生网络故障,断线之后重连,如果主从的状态不一致,会使用SYNC命令全部同步,显然全部同步的操作并不是都需要的.

新版本的复制功能:

    新版本使用复制挤压缓冲区,复制偏移量,服务器ID来实现部分同步.
    主服务器根据从服务器发送过来的offset,如果offset仍然在复制积压缓冲区内,那么执行部分同步,否则执行全部同步



从服务器命令的发送

    - 从服务器没有复制过任何主服务器,或者从服务器执行过slaveof no one,表示第一次复制,所以是全部复制 发送命令 PSYNC ? -1
    - 如果从服务器已经复制过某个主服务器,发送PSYNC <runid> <offset>:其中runid是上一次的复制的主服务器返回的ID,而offset则是从服务器当前的复制偏移量.

主服务器命令的接收与回复:

    - 主服务器返回 +FULLRESYNC <runid> <offset> 表示全量复制
    - 主服务器返回 + CONTINUE 表示部分同步

**心跳检测**
    
    从服务器每隔一秒会向主服务器发送命令 REPLCONF ACK <replication_offset>复制偏移量
    
    三个作用:
    1. 检测主从服务器的网络状况
    2. 检测命令丢失,实现主从状态一直
    3. 辅助实现min-salve选项

###### 哨兵
> Sentinel是Redis高可用的解决方案:通过一个或多个Sentinel实例组成的Sentinel系统来监视任意多个主服务器,以及主服务器的从服务器,并在主服务器下线之后,自动将主服务器下属中的一个从服务器转化为新的主服务器,然后由新的主服务器代替已下线的主服务器继续工作.

哨兵是redis服务器的一种特殊模式

**Sentinel和主从服务器的信息交互：**
    
    1. Sentinel与主从服务器建立命令连接,通过INFO获取主从服务的信息,并更新响应的实例.
    2. Sentinel发布并订阅在主从服务器创建的频道，_sentinel_channel:hello,通过订阅频道,可以Sentinel可以发现新的Sentinel,并为新的Sentinel创建实例.
    3. Sentinel之间仅仅通过命令连接,不会创建订阅.

**故障转移:**
    
    1. 主观下线 Sentinel通过ping命令与主服务通信,,如果在参数(down-after_milleseconds)规定的时间内没有获取合法响应,认为主观下线.
    2. 客观下线 认为主服务器主观下线的服务器,会向其他的Sentinel发送命令,询问是否认可目标的主服务器下线(判断为主观下线),认可数达到目标参数后,改Sentinel认为主服务器客观下线,每个Sentinel设置的客观下线的达标数量不一定一致.
    3. 选举领头Sentinel 每次选举epoch就会增加,Sentinel之间互相发送命令,目标Sentinel是否认可源Sentinel,先到先得原则,Sentinel的认可数量达到Quorum时,设置为领头Sentinel.
    4. 故障迁移 
    在从服务器中选出主服务器(剔除已经下线的,与之前主服务器连接状况不好的,选择复制偏移量大的,服务器id小的),执行`slaveof no one`.
    剩余的从服务器与新的主服务器建立主从关系,复制数据.
    讲已下线的主服务器设置为从服务器.
    
###### 集群 Cluster
> Redis集群是Reids的分布式数据库解决防范,集群通过分片(sharding)来进行数据共享,并提供复制和故障转移.

**集群的搭建:**
    
    节点连接
    
    通过 cluster meet <host> <port> 搭建集群
    
    指派槽
    redis将集群的数据库分为16384个槽,每个集群节点对应一个槽点数组.每个键值通过HASH_SLOT=CRC16(key) & 16384
    命令:aluster addslots [slot] 指派槽
    
    MOVED错误
    当节点发现键所在的槽不在自己的负责范围内,节点会向客户端返回MOVED错误,指引客户端转向正在负责槽的节点. moved <slot> <host>:<port>
    
    一个集群客户端通常会与多个节点创建套字节连接,而节点转向就是换一个Socket连接.
    
    ACK
    重新分片会导致ACK错误.数据迁移的过程中,如果在源节点没有找到目标key,会向客户端返回ACK错误,指引客户端转向正在导入槽的目标节点.
    
    故障迁移:
    1.集群中的每个节点都会向其他节点定时发送PING消息,如果接收消息的节点没有在规定的时间内相应PONG,那么发送消息的节点会将接收消息的节点标记为疑似下线.
    2.集群中的各个节点会互相交换信息,交换某个节点的下线状态,如果超过N/2+1的节点认为某个节点下线,则直接标记该节点已下线,并广播通知所有节点.所有节点会将该节点标记为已下线.
    3.从节点接收到广播通知,发现自己的主节点已下线,会向集群广播一条消息,意味着竞选新的主节点.
    4.所有有投票权的主节点会进行投票,投票权只有一次,所有会投接收到的第一个广播消息的发送节点,主节点会发送消息给从节点,表示支持.
    5.从节点收到大于等于N/2+1张支持的票时,称为新的主节点.
    6.新的主节点执行slaveof no one,撤销所有已下线主节点的槽指派,并将槽指派给自己.然后发送广播消息,通知其他节点,自己成为新的主节点,继续执行指令.
    
    

    集群节点总结:
    1. 不能使用事务
    2. 处理批命令比较麻烦,一般较少的量情况下,建议串行处理
    3. 集群节点的数据库只能是0号数据库,而单机可以划分16个数据库
    
扩展:

[为什么redis集群的槽式16384个](https://www.cnblogs.com/rjzheng/p/11430592.html)
    
[redis集群面试题](https://www.cnblogs.com/rjzheng/p/10360619.html)

[Quorom机制](https://www.cnblogs.com/zz-ksw/p/12772605.html)
    

#### 缓存穿透 雪崩，击穿

#### 缓存的三种使用策 淘汰机制

#### 分布式锁  

#### redission  

#### 布隆过滤器